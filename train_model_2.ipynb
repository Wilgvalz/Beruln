{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5c55f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataset_dv_my.csv') #load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b522419",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.utils import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertConfig\n",
    "from transformers import AdamW, BertForSequenceClassification, get_linear_schedule_with_warmup\n",
    "from tqdm import tqdm, trange\n",
    "import pandas as pd\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from peft import PeftModel, PeftConfig, get_peft_model, LoraConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c741152c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7c60db56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>func</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>static boolean ReadICCProfile(j_decompress_ptr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>zzip_mem_disk_load(ZZIP_MEM_DISK* dir, ZZIP_DI...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>int rsa_pkcs1_decrypt( rsa_context *ctx,\\n    ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>static int ehci_process_itd(EHCIState *ehci,\\n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>GF_Filter *gf_fs_load_filter(GF_FilterSession ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23595</th>\n",
       "      <td>23595</td>\n",
       "      <td>static int rtw_wx_get_retry(struct net_device ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23596</th>\n",
       "      <td>23596</td>\n",
       "      <td>int\\nskb_zerocopy(struct sk_buff *to, struct s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23597</th>\n",
       "      <td>23597</td>\n",
       "      <td>static CURLcode http_output_basic(struct conne...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23598</th>\n",
       "      <td>23598</td>\n",
       "      <td>static double mp_bitwise_not(_cimg_math_...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23599</th>\n",
       "      <td>23599</td>\n",
       "      <td>megasas_check_and_restore_queue_depth(struct m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23600 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                               func  target\n",
       "0               0  static boolean ReadICCProfile(j_decompress_ptr...       1\n",
       "1               1  zzip_mem_disk_load(ZZIP_MEM_DISK* dir, ZZIP_DI...       1\n",
       "2               2  int rsa_pkcs1_decrypt( rsa_context *ctx,\\n    ...       1\n",
       "3               3  static int ehci_process_itd(EHCIState *ehci,\\n...       1\n",
       "4               4  GF_Filter *gf_fs_load_filter(GF_FilterSession ...       1\n",
       "...           ...                                                ...     ...\n",
       "23595       23595  static int rtw_wx_get_retry(struct net_device ...       0\n",
       "23596       23596  int\\nskb_zerocopy(struct sk_buff *to, struct s...       0\n",
       "23597       23597  static CURLcode http_output_basic(struct conne...       0\n",
       "23598       23598        static double mp_bitwise_not(_cimg_math_...       0\n",
       "23599       23599  megasas_check_and_restore_queue_depth(struct m...       0\n",
       "\n",
       "[23600 rows x 3 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "286615b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sen = []\n",
    "for i in range(23600):\n",
    "  sen.append(data['func'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "722f4da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sen2 = ['[CLS]' + sentence + '[SEP]' for sentence in sen]\n",
    "lab = data.target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e6194c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenize the first sentence: \n",
      "['[CLS]', 'static', 'boo', '##lean', 'read', '##ic', '##cp', '##ro', '##fi', '##le', '(', 'j', '_', 'deco', '##mp', '##ress', '_', 'pt', '##r', 'jp', '##eg', '_', 'info', ')', '{', 'char', 'magic', '##k', '[', '12', ']', ';', 'error', '##mana', '##ger', '*', 'error', '_', 'manager', ';', 'exception', '##in', '##fo', '*', 'exception', ';', 'image', '*', 'image', ';', 'magic', '##k', '##bo', '##ole', '##ant', '##ype', 'status', ';', 'register', 'ss', '##ize', '_', 't', 'i', ';', 'register', 'unsigned', 'char', '*', 'p', ';', 'size', '_', 't', 'length', ';', 'string', '##in', '##fo', '*', 'icc', '_', 'profile', ',', '*', 'profile', ';', '/', '*', 'read', 'color', 'profile', '.', '*', '/', 'length', '=', '(', 'size', '_', 't', ')', '(', '(', 'size', '_', 't', ')', 'get', '##cha', '##rac', '##ter', '(', 'jp', '##eg', '_', 'info', ')', '<', '<', '8', ')', ';', 'length', '+', '=', '(', 'size', '_', 't', ')', 'get', '##cha', '##rac', '##ter', '(', 'jp', '##eg', '_', 'info', ')', ';', 'length', '-', '=', '2', ';', 'if', '(', 'length', '<', '=', '14', ')', '{', 'while', '(', 'length', '-', '-', '>', '0', ')', 'if', '(', 'get', '##cha', '##rac', '##ter', '(', 'jp', '##eg', '_', 'info', ')', '=', '=', 'e', '##of', ')', 'break', ';', 'return', '(', 'true', ')', ';', '}', 'for', '(', 'i', '=', '0', ';', 'i', '<', '12', ';', 'i', '+', '+', ')', 'magic', '##k', '[', 'i', ']', '=', '(', 'char', ')', 'get', '##cha', '##rac', '##ter', '(', 'jp', '##eg', '_', 'info', ')', ';', 'if', '(', 'local', '##ec', '##omp', '##are', '(', 'magic', '##k', ',', 'icc', '_', 'profile', ')', '!', '=', '0', ')', '{', '/', '*', 'not', 'a', 'icc', 'profile', ',', 'return', '.', '*', '/', 'for', '(', 'i', '=', '0', ';', 'i', '<', '(', 'ss', '##ize', '_', 't', ')', '(', 'length', '-', '12', ')', ';', 'i', '+', '+', ')', 'if', '(', 'get', '##cha', '##rac', '##ter', '(', 'jp', '##eg', '_', 'info', ')', '=', '=', 'e', '##of', ')', 'break', ';', 'return', '(', 'true', ')', ';', '}', '(', 'void', ')', 'get', '##cha', '##rac', '##ter', '(', 'jp', '##eg', '_', 'info', ')', ';', '/', '*', 'id', '*', '/', '(', 'void', ')', 'get', '##cha', '##rac', '##ter', '(', 'jp', '##eg', '_', 'info', ')', ';', '/', '*', 'markers', '*', '/', 'length', '-', '=', '14', ';', 'error', '_', 'manager', '=', '(', 'error', '##mana', '##ger', '*', ')', 'jp', '##eg', '_', 'info', '-', '>', 'client', '_', 'data', ';', 'exception', '=', 'error', '_', 'manager', '-', '>', 'exception', ';', 'image', '=', 'error', '_', 'manager', '-', '>', 'image', ';', 'profile', '=', 'b', '##lo', '##bt', '##ost', '##ring', '##in', '##fo', '(', '(', 'con', '##st', 'void', '*', ')', 'null', ',', 'length', ')', ';', 'if', '(', 'profile', '=', '=', '(', 'string', '##in', '##fo', '*', ')', 'null', ')', '{', '(', 'void', ')', 'throw', '##ma', '##gic', '##ke', '##x', '##ception', '(', 'exception', ',', 'get', '##ma', '##gic', '##km', '##od', '##ule', '(', ')', ',', 'resource', '##lim', '##iter', '##ror', ',', '\"', 'memory', '##all', '##ocation', '##fa', '##iled', '\"', ',', '\"', '`', '%', 's', \"'\", '\"', ',', 'image', '-', '>', 'file', '##name', ')', ';', 'return', '(', 'false', ')', ';', '}', 'error', '_', 'manager', '-', '>', 'profile', '=', 'profile', ';', 'p', '=', 'gets', '##tri', '##ng', '##in', '##fo', '##da', '##tum', '(', 'profile', ')', ';', 'for', '(', 'i', '=', '0', ';', 'i', '<', '(', 'ss', '##ize', '_', 't', ')', 'length', ';', 'i', '+', '+', ')', '{', 'int', 'c', ';', 'c', '=', 'get', '##cha', '##rac', '##ter', '(', 'jp', '##eg', '_', 'info', ')', ';', 'if', '(', 'c', '=', '=', 'e', '##of', ')', 'break', ';', '*', 'p', '+', '+', '=', '(', 'unsigned', 'char', ')', 'c', ';', '}', 'if', '(', 'i', '!', '=', '(', 'ss', '##ize', '_', 't', ')', 'length', ')', '{', 'profile', '=', 'destroys', '##tri', '##ng', '##in', '##fo', '(', 'profile', ')', ';', '(', 'void', ')', 'throw', '##ma', '##gic', '##ke', '##x', '##ception', '(', 'exception', ',', 'get', '##ma', '##gic', '##km', '##od', '##ule', '(', ')', ',', 'corrupt', '##ima', '##gee', '##rro', '##r', ',', '\"', 'insufficient', '##ima', '##ged', '##ata', '##in', '##fi', '##le', '\"', ',', '\"', '`', '%', 's', \"'\", '\"', ',', 'image', '-', '>', 'file', '##name', ')', ';', 'return', '(', 'false', ')', ';', '}', 'error', '_', 'manager', '-', '>', 'profile', '=', 'null', ';', 'icc', '_', 'profile', '=', '(', 'string', '##in', '##fo', '*', ')', 'get', '##ima', '##ge', '##pro', '##fi', '##le', '(', 'image', ',', '\"', 'icc', '\"', ')', ';', 'if', '(', 'icc', '_', 'profile', '!', '=', '(', 'string', '##in', '##fo', '*', ')', 'null', ')', '{', 'con', '##cate', '##nate', '##st', '##ring', '##in', '##fo', '(', 'icc', '_', 'profile', ',', 'profile', ')', ';', 'profile', '=', 'destroys', '##tri', '##ng', '##in', '##fo', '(', 'profile', ')', ';', '}', 'else', '{', 'status', '=', 'set', '##ima', '##ge', '##pro', '##fi', '##le', '(', 'image', ',', '\"', 'icc', '\"', ',', 'profile', ',', 'exception', ')', ';', 'profile', '=', 'destroys', '##tri', '##ng', '##in', '##fo', '(', 'profile', ')', ';', 'if', '(', 'status', '=', '=', 'magic', '##k', '##fa', '##ls', '##e', ')', '{', '(', 'void', ')', 'throw', '##ma', '##gic', '##ke', '##x', '##ception', '(', 'exception', ',', 'get', '##ma', '##gic', '##km', '##od', '##ule', '(', ')', ',', 'resource', '##lim', '##iter', '##ror', ',', '\"', 'memory', '##all', '##ocation', '##fa', '##iled', '\"', ',', '\"', '`', '%', 's', \"'\", '\"', ',', 'image', '-', '>', 'file', '##name', ')', ';', 'return', '(', 'false', ')', ';', '}', '}', 'if', '(', 'image', '-', '>', 'de', '##bu', '##g', '!', '=', 'magic', '##k', '##fa', '##ls', '##e', ')', '(', 'void', ')', 'log', '##ma', '##gic', '##ke', '##vent', '(', 'code', '##re', '##vent', ',', 'get', '##ma', '##gic', '##km', '##od', '##ule', '(', ')', ',', '\"', 'profile', ':', 'icc', ',', '%', '.', '20', '##g', 'bytes', '\"', ',', '(', 'double', ')', 'length', ')', ';', 'return', '(', 'true', ')', ';', '}', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "tokenizer2 = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "tokenized_texts2 = [tokenizer2.tokenize(sent) for sent in sen2]\n",
    "print('tokenize the first sentence...: ')\n",
    "#print(tokenized_texts2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f098ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 128 #for vocab\n",
    "input_ids2 = [tokenizer2.convert_tokens_to_ids(x) for x in tokenized_texts2]\n",
    "input_ids2 = pad_sequences(input_ids2, maxlen = MAX_LEN, dtype = 'long', truncating = 'post', padding = 'post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ac1ad1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_masks2 = []\n",
    "for seq in input_ids2:\n",
    "  seq_mask2 = [float(i>0) for i in seq]\n",
    "  attention_masks2.append(seq_mask2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb0ce71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs2, validation_inputs2, train_labels2, validation_labels2 = train_test_split(input_ids2, lab, random_state = 2019,test_size = 0.1)\n",
    "train_masks2, validation_masks2, _ , _ = train_test_split(attention_masks2, input_ids2, random_state = 2019, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97dc7e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs2 = torch.tensor(train_inputs2)\n",
    "validation_inputs2 = torch.tensor(validation_inputs2)\n",
    "train_labels2 = torch.tensor(train_labels2)\n",
    "validation_labels2 = torch.tensor(validation_labels2)\n",
    "train_masks2 = torch.tensor(train_masks2)\n",
    "validation_masks2 = torch.tensor(validation_masks2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bdea92af",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size2 = 32\n",
    "\n",
    "train_data2 = TensorDataset(train_inputs2, train_masks2, train_labels2)\n",
    "train_sampler2 = RandomSampler(train_data2)\n",
    "train_dataloader2 = DataLoader(train_data2, sampler = train_sampler2, batch_size = batch_size2)\n",
    "validation_data2 = TensorDataset(validation_inputs2, validation_masks2, validation_labels2)\n",
    "validation_sampler2 = SequentialSampler(validation_data2)\n",
    "validation_dataloader2 = DataLoader(validation_data2, sampler = validation_sampler2, batch_size = batch_size2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31f335e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.41.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel, BertConfig\n",
    "configuration = BertConfig()\n",
    "\n",
    "model = BertModel(configuration)\n",
    "\n",
    "configuration = model.config\n",
    "print(configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9578d83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(task_type=\"SEQ_CLS\",\n",
    "                        r=4,\n",
    "                        lora_alpha=32,\n",
    "                        lora_dropout=0.01,\n",
    "                        target_modules = ['dense'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0c010f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertModel(\n",
      "  (embeddings): BertEmbeddings(\n",
      "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "    (position_embeddings): Embedding(512, 768)\n",
      "    (token_type_embeddings): Embedding(2, 768)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): BertEncoder(\n",
      "    (layer): ModuleList(\n",
      "      (0-11): 12 x BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pooler): BertPooler(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (activation): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32f72613",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): BertForSequenceClassification(\n",
       "    (bert): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-11): 12 x BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "model = nn.DataParallel(model)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ed56bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 450,050 || all params: 109,933,828 || trainable%: 0.4094\n"
     ]
    }
   ],
   "source": [
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "aff00d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "\n",
    "optimizer_grouped_parameters = [\n",
    "    \n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.1},\n",
    "\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.0}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b14dd613",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_parameters = [p for n, p in model.named_parameters() if 'layer.3' in n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4bc9a388",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_sample = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)][:2],\n",
    "     'weight_decay_rate': 0.1},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)][:2],\n",
    "     'weight_decay_rate': 0.0}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3db59fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lera/.local/lib/python3.10/site-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "optimizer = AdamW(optimizer_grouped_parameters,\n",
    "                  lr = 2e-5, \n",
    "                  eps = 1e-8 \n",
    "                  )\n",
    "\n",
    "total_steps = len(train_dataloader2) * epochs\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                            num_warmup_steps = 4, \n",
    "                                            num_training_steps = total_steps)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e2f9407b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ab15b82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "226b11c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.module.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c02ce06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: static int\n",
      "Prediction: [-0.21009256  0.08892278]\n",
      "Sofmax probabilities [0.4257982 0.5742018]\n",
      "Prediction: 1\n",
      "True label: 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def softmax(logits):\n",
    "    e = np.exp(logits)\n",
    "    return e / np.sum(e)\n",
    "     \n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "model.eval()\n",
    "\n",
    "raw_predictions, predicted_classes, true_labels = [], [], []\n",
    "\n",
    "for batch in prediction_dataloader:\n",
    "  #Add batch to GPU\n",
    "  batch = tuple(t.to(device) for t in batch)\n",
    " \n",
    "  b_input_ids, b_input_mask, b_labels = batch\n",
    "   \n",
    "  with torch.no_grad():\n",
    "    \n",
    "    outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    " \n",
    "  logits = outputs['logits'].detach().cpu().numpy()\n",
    "  label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "  b_input_ids = b_input_ids.to('cpu').numpy()\n",
    "  batch_sentences = [tokenizer2.decode(input_ids, skip_special_tokens=True) for input_ids in b_input_ids]\n",
    "  probabilities = torch.nn.functional.softmax(torch.tensor(logits), dim=-1)\n",
    "\n",
    "  batch_predictions = np.argmax(probabilities, axis=1)\n",
    "    \n",
    "\"\"\"\n",
    "  for i, sentence in enumerate(batch_sentences):\n",
    "    print(f\"sentence: {sentence}\")\n",
    "    print(f\"prediction: {logits[i]}\")\n",
    "    print(f\"sofmax probabilities\", softmax(logits[i]))\n",
    "    print(f\"prediction: {batch_predictions[i]}\")\n",
    "    print(f\"true label: {label_ids[i]}\")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2cd02546",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   0%|                                             | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.6495484132544104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   5%|█▊                                  | 1/20 [01:50<34:54, 110.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6058558558558559\n",
      "Train loss: 0.6305886612060558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  10%|███▌                                | 2/20 [03:40<33:09, 110.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6386542792792792\n",
      "Train loss: 0.6227152653218034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  15%|█████▍                              | 3/20 [05:31<31:20, 110.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6489301801801802\n",
      "Train loss: 0.6169944242630379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|███████▏                            | 4/20 [07:22<29:30, 110.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6145833333333333\n",
      "Train loss: 0.612427595419338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  25%|█████████                           | 5/20 [09:13<27:40, 110.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6566722972972973\n",
      "Train loss: 0.60623264474323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  30%|██████████▊                         | 6/20 [11:03<25:50, 110.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6679335585585586\n",
      "Train loss: 0.598901859024562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  35%|████████████▌                       | 7/20 [12:54<23:59, 110.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6768018018018018\n",
      "Train loss: 0.5921210662338389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  40%|██████████████▍                     | 8/20 [14:45<22:09, 110.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6759572072072072\n",
      "Train loss: 0.5891599909189236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  45%|████████████████▏                   | 9/20 [16:36<20:18, 110.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6794763513513513\n",
      "Train loss: 0.5828587656997772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  50%|█████████████████▌                 | 10/20 [18:27<18:27, 110.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6786317567567568\n",
      "Train loss: 0.5781098961471075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  55%|███████████████████▎               | 11/20 [20:17<16:37, 110.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.690456081081081\n",
      "Train loss: 0.5722423330936806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  60%|█████████████████████              | 12/20 [22:08<14:46, 110.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6872184684684685\n",
      "Train loss: 0.5662261114781162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  65%|██████████████████████▊            | 13/20 [23:59<12:55, 110.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6897522522522522\n",
      "Train loss: 0.5644104038196874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  70%|████████████████████████▌          | 14/20 [25:50<11:04, 110.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6803209459459459\n",
      "Train loss: 0.5610161968562977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  75%|██████████████████████████▎        | 15/20 [27:41<09:13, 110.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6841216216216216\n",
      "Train loss: 0.5564439746001398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  80%|████████████████████████████       | 16/20 [29:31<07:23, 110.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.692286036036036\n",
      "Train loss: 0.5527312290596674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  85%|█████████████████████████████▊     | 17/20 [31:22<05:32, 110.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.691722972972973\n",
      "Train loss: 0.5498418339404715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  90%|███████████████████████████████▌   | 18/20 [33:13<03:41, 110.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6929898648648649\n",
      "Train loss: 0.5488000846052744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  95%|█████████████████████████████████▎ | 19/20 [35:04<01:50, 110.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6939752252252251\n",
      "Train loss: 0.5467394755098475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|███████████████████████████████████| 20/20 [36:54<00:00, 110.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.695242117117117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "t = []\n",
    "\n",
    "train_loss_set = []\n",
    "\n",
    "for _ in trange(epochs, desc=\"Epoch\"):\n",
    "\n",
    "  model.train()\n",
    "\n",
    "  tr_loss = 0\n",
    "  nb_tr_examples, nb_tr_steps = 0, 0\n",
    "\n",
    "  for step, batch in enumerate(train_dataloader2):\n",
    "   \n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    \n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "   \n",
    "    outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "    loss = outputs['loss']\n",
    "    train_loss_set.append(loss.item())\n",
    "  \n",
    "    loss.backward()\n",
    "   \n",
    "    optimizer.step()\n",
    "    \n",
    "    scheduler.step()\n",
    "\n",
    "    tr_loss += loss.item()\n",
    "    nb_tr_examples += b_input_ids.size(0)\n",
    "    nb_tr_steps += 1\n",
    "\n",
    "  print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
    "\n",
    "  \n",
    "  model.eval()\n",
    "\n",
    "\n",
    "  eval_loss, eval_accuracy = 0, 0\n",
    "  nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "\n",
    "  for batch in validation_dataloader2:\n",
    "   \n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    " \n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "     \n",
    "    with torch.no_grad():\n",
    "      \n",
    "      logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "\n",
    "    \n",
    "    logits = logits['logits'].detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "    tmp_eval_accuracy = calc_accuracy(logits, label_ids)\n",
    "\n",
    "    eval_accuracy += tmp_eval_accuracy\n",
    "    nb_eval_steps += 1\n",
    "\n",
    "  print(\"Validation accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cc23fc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open('vuln_job_1.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62aa008",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
